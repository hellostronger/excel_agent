"""Flask backend for Excel Intelligent Agent System with RAG capabilities."""

import os
import asyncio
import sys
import tempfile
import uuid
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename

# Add src directory to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Try to import the agent system with fallback
try:
    from excel_agent.core.orchestrator import Orchestrator
    from excel_agent.mcp.agent_configs import initialize_mcp_system, initialize_all_agent_mcp
    AGENT_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Agent system not available: {e}")
    AGENT_AVAILABLE = False

app = Flask(__name__)
CORS(app)

# Configuration
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size
app.config['UPLOAD_FOLDER'] = tempfile.mkdtemp()

# Allowed file extensions
ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'xlsm'}

# Global variables
orchestrator = None
uploaded_files = {}
mcp_initialized = False


def allowed_file(filename):
    """Check if file extension is allowed."""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


async def initialize_agent_system():
    """Initialize the agent system with MCP capabilities."""
    global orchestrator, mcp_initialized
    
    if not AGENT_AVAILABLE:
        return False
    
    try:
        print("Initializing Agent System...")
        
        # Initialize MCP system
        initialize_mcp_system()
        await initialize_all_agent_mcp()
        mcp_initialized = True
        
        # Initialize orchestrator
        orchestrator = Orchestrator()
        
        print("Agent System initialized successfully!")
        return True
        
    except Exception as e:
        print(f"Failed to initialize agent system: {e}")
        return False


def run_async(coro):
    """Run async function in sync context."""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # If loop is already running, create a new task
            return loop.create_task(coro)
        else:
            return loop.run_until_complete(coro)
    except RuntimeError:
        # No event loop, create a new one
        return asyncio.run(coro)


@app.route('/')
def index():
    """Serve the main page."""
    return render_template('index.html')


@app.route('/api/status')
def get_status():
    """Get system status."""
    status = {
        'agent_available': AGENT_AVAILABLE,
        'mcp_initialized': mcp_initialized,
        'orchestrator_ready': orchestrator is not None,
        'upload_folder': app.config['UPLOAD_FOLDER'],
        'max_file_size': app.config['MAX_CONTENT_LENGTH'],
        'allowed_extensions': list(ALLOWED_EXTENSIONS)
    }
    
    if orchestrator and mcp_initialized:
        try:
            # Get MCP status if available
            mcp_status = asyncio.run(orchestrator.get_mcp_status())
            status['mcp_status'] = mcp_status
        except Exception as e:
            status['mcp_error'] = str(e)
    
    return jsonify(status)


@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Handle file upload."""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'Invalid file type. Please upload Excel files (.xlsx, .xls, .xlsm)'}), 400
        
        # Generate unique filename
        file_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{file_id}_{filename}")
        
        # Save file
        file.save(file_path)
        
        # Store file info
        file_info = {
            'file_id': file_id,
            'original_name': filename,
            'file_path': file_path,
            'size': os.path.getsize(file_path),
            'upload_time': datetime.now().isoformat(),
            'processed': False
        }
        
        uploaded_files[file_id] = file_info
        
        return jsonify({
            'success': True,
            'file_id': file_id,
            'filename': filename,
            'size': file_info['size'],
            'message': 'File uploaded successfully'
        })
        
    except Exception as e:
        return jsonify({'error': f'Upload failed: {str(e)}'}), 500


@app.route('/api/process/<file_id>', methods=['POST'])
def process_file(file_id):
    """Process uploaded file using the agent system."""
    try:
        if file_id not in uploaded_files:
            return jsonify({'error': 'File not found'}), 404
        
        file_info = uploaded_files[file_id]
        
        if not AGENT_AVAILABLE or not orchestrator:
            # Return mock response if agent system not available
            return jsonify({
                'success': True,
                'file_id': file_id,
                'processed': True,
                'mock_mode': True,
                'steps': [
                    {'step': 'upload', 'status': 'completed', 'message': 'File uploaded'},
                    {'step': 'ingest', 'status': 'completed', 'message': 'File parsed (mock)'},
                    {'step': 'profile', 'status': 'completed', 'message': 'Data analyzed (mock)'},
                    {'step': 'ready', 'status': 'completed', 'message': 'Ready for queries (mock)'}
                ],
                'metadata': {
                    'sheets': ['Sheet1', 'Data', 'Summary'],
                    'total_rows': 1234,
                    'total_columns': 8,
                    'file_size': file_info['size']
                },
                'preview': {
                    'columns': ['Product', 'Sales', 'Quantity', 'Date', 'Category', 'Price', 'Profit', 'Region'],
                    'sample_data': [
                        ['Laptop', 15000, 5, '2024-01-15', 'Electronics', 3000, 2000, 'North'],
                        ['Phone', 8000, 10, '2024-01-16', 'Electronics', 800, 1200, 'South'],
                        ['Tablet', 6000, 8, '2024-01-17', 'Electronics', 750, 800, 'East']
                    ]
                }
            })
        
        # Process with real agent system
        async def process_with_agents():
            file_path = file_info['file_path']
            
            # Use orchestrator to process file
            result = await orchestrator.process_user_request(
                user_request="Please ingest and analyze this Excel file",
                file_path=file_path,
                context={'file_id': file_id}
            )
            
            return result
        
        # Run async processing
        result = run_async(process_with_agents())
        
        # Update file info
        file_info['processed'] = True
        file_info['process_result'] = result
        
        return jsonify({
            'success': True,
            'file_id': file_id,
            'processed': True,
            'result': result
        })
        
    except Exception as e:
        return jsonify({'error': f'Processing failed: {str(e)}'}), 500


@app.route('/api/query', methods=['POST'])
def query_data():
    """Handle user queries about the data."""
    try:
        data = request.get_json()
        file_id = data.get('file_id')
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({'error': 'Query cannot be empty'}), 400
        
        if file_id not in uploaded_files:
            return jsonify({'error': 'File not found'}), 404
        
        file_info = uploaded_files[file_id]
        
        if not AGENT_AVAILABLE or not orchestrator:
            # Return mock response if agent system not available
            mock_responses = generate_mock_response(query, file_info)
            return jsonify({
                'success': True,
                'query': query,
                'response': mock_responses['analysis'],
                'generated_code': mock_responses['code'],
                'mock_mode': True,
                'execution_time': 2.5,
                'insights': mock_responses.get('insights', []),
                'visualizations': mock_responses.get('visualizations', [])
            })
        
        # Process with real agent system
        async def query_with_agents():
            file_path = file_info['file_path']
            
            # Use orchestrator to process query
            result = await orchestrator.process_user_request(
                user_request=query,
                file_path=file_path,
                context={
                    'file_id': file_id,
                    'previous_processing': file_info.get('process_result')
                }
            )
            
            return result
        
        # Run async query processing
        result = run_async(query_with_agents())
        
        return jsonify({
            'success': True,
            'query': query,
            'response': result.get('final_result', 'Analysis completed'),
            'generated_code': result.get('generated_code', ''),
            'workflow_steps': result.get('steps', []),
            'execution_time': result.get('execution_time', 0),
            'status': result.get('status', 'completed')
        })
        
    except Exception as e:
        return jsonify({'error': f'Query failed: {str(e)}'}), 500


def generate_mock_response(query, file_info):
    """Generate mock responses for testing when agent system is not available."""
    query_lower = query.lower()
    
    if 'ç»Ÿè®¡' in query_lower or 'åŸºæœ¬ä¿¡æ¯' in query_lower:
        return {
            'analysis': f"""ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æç»“æœ

åŸºäºæ‚¨ä¸Šä¼ çš„æ–‡ä»¶ "{file_info['original_name']}"ï¼š

ğŸ“‹ æ•°æ®æ¦‚è§ˆï¼š
â€¢ æ€»è¡Œæ•°: 1,234 è¡Œ
â€¢ æ€»åˆ—æ•°: 8 åˆ—
â€¢ æ–‡ä»¶å¤§å°: {file_info['size']} bytes
â€¢ æ•°æ®ç±»å‹: 4ä¸ªæ•°å€¼åˆ—, 3ä¸ªæ–‡æœ¬åˆ—, 1ä¸ªæ—¥æœŸåˆ—

ğŸ“ˆ æ•°å€¼åˆ—ç»Ÿè®¡ï¼š
â€¢ é”€å”®é¢: å¹³å‡å€¼ Â¥8,547, æœ€å¤§å€¼ Â¥25,000, æœ€å°å€¼ Â¥1,200
â€¢ æ•°é‡: å¹³å‡å€¼ 15.6, æœ€å¤§å€¼ 100, æœ€å°å€¼ 1
â€¢ åˆ©æ¶¦ç‡: å¹³å‡å€¼ 23.4%, æ ‡å‡†å·® 8.9%

ğŸ” æ•°æ®è´¨é‡ï¼š
â€¢ å®Œæ•´æ€§: 98.7% (16ä¸ªç¼ºå¤±å€¼)
â€¢ é‡å¤è®°å½•: 3æ¡
â€¢ å¼‚å¸¸å€¼: åœ¨é”€å”®é¢åˆ—å‘ç°5ä¸ªæ½œåœ¨å¼‚å¸¸å€¼

ğŸ’¡ å…³é”®æ´å¯Ÿï¼š
1. ç”µå­äº§å“ç±»åˆ«é”€å”®é¢å æ€»é”€å”®é¢çš„68%
2. Q4é”€å”®é¢æ¯”Q3å¢é•¿äº†15.3%
3. å‘¨äº”å’Œå‘¨å…­æ˜¯é”€å”®é«˜å³°æœŸ""",
            
            'code': f'''import pandas as pd
import numpy as np

# è¯»å–Excelæ–‡ä»¶
df = pd.read_excel('{file_info['original_name']}')

# åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
print("æ•°æ®å½¢çŠ¶:", df.shape)
print("æ•°æ®ç±»å‹:")
print(df.dtypes)

# æ•°å€¼åˆ—ç»Ÿè®¡
numeric_cols = df.select_dtypes(include=[np.number]).columns
print("æ•°å€¼åˆ—ç»Ÿè®¡:")
print(df[numeric_cols].describe())

# ç¼ºå¤±å€¼æ£€æŸ¥
print("ç¼ºå¤±å€¼ç»Ÿè®¡:")
print(df.isnull().sum())'''
        }
        
    elif 'å¼‚å¸¸' in query_lower or 'ç¦»ç¾¤ç‚¹' in query_lower:
        return {
            'analysis': """ğŸ” å¼‚å¸¸å€¼æ£€æµ‹ç»“æœ

ä½¿ç”¨IQRæ–¹æ³•å’ŒZ-Scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼ï¼š

ğŸš¨ å‘ç°çš„å¼‚å¸¸å€¼ï¼š
â€¢ é”€å”®é¢åˆ—: 5ä¸ªå¼‚å¸¸å€¼
  - ç¬¬67è¡Œ: Â¥87,500 (Z-score: 4.2)
  - ç¬¬156è¡Œ: Â¥0 (å¯èƒ½å½•å…¥é”™è¯¯)
  - ç¬¬234è¡Œ: Â¥125,000 (Z-score: 6.8)

â€¢ æ•°é‡åˆ—: 2ä¸ªå¼‚å¸¸å€¼
  - ç¬¬123è¡Œ: 999 (æ‰¹å‘è®¢å•)
  - ç¬¬567è¡Œ: 0 (é›¶æ•°é‡å¼‚å¸¸)

ğŸ’¡ å¤„ç†å»ºè®®ï¼š
1. éªŒè¯æå€¼çš„çœŸå®æ€§
2. æ£€æŸ¥é›¶å€¼å’Œè´Ÿå€¼
3. è€ƒè™‘ä¸šåŠ¡è§„åˆ™è¿›è¡Œæ¸…æ´—""",
            
            'code': '''import pandas as pd
import numpy as np
from scipy import stats

def detect_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] < lower_bound) | (df[column] > upper_bound)]

# æ£€æµ‹å¼‚å¸¸å€¼
outliers = detect_outliers_iqr(df, 'sales_amount')
print(f"å‘ç° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")'''
        }
        
    elif 'ç›¸å…³' in query_lower or 'å…³è”' in query_lower:
        return {
            'analysis': """ğŸ”— ç›¸å…³æ€§åˆ†æç»“æœ

æ•°æ®ç›¸å…³æ€§åˆ†ææ˜¾ç¤ºï¼š

ğŸ“ˆ å¼ºæ­£ç›¸å…³ (r > 0.7):
â€¢ é”€å”®é¢ â†” åˆ©æ¶¦: r = 0.89
â€¢ ä»·æ ¼ â†” åˆ©æ¶¦ç‡: r = 0.76
â€¢ å¹¿å‘ŠæŠ•å…¥ â†” é”€å”®é¢: r = 0.72

ğŸ“‰ è´Ÿç›¸å…³ (r < -0.3):
â€¢ æŠ˜æ‰£ç‡ â†” åˆ©æ¶¦ç‡: r = -0.65
â€¢ åº“å­˜é‡ â†” é”€å”®é€Ÿåº¦: r = -0.45

ğŸ’¡ ä¸šåŠ¡æ´å¯Ÿï¼š
1. é”€å”®é¢ä¸åˆ©æ¶¦é«˜åº¦ç›¸å…³ï¼Œå®šä»·ç­–ç•¥ç¨³å®š
2. å¹¿å‘ŠæŠ•å…¥ROIè‰¯å¥½
3. æŠ˜æ‰£ç­–ç•¥éœ€è¦ä¼˜åŒ–""",
            
            'code': '''import seaborn as sns
import matplotlib.pyplot as plt

# è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
numeric_cols = df.select_dtypes(include=[np.number]).columns
correlation_matrix = df[numeric_cols].corr()

# åˆ›å»ºçƒ­åŠ›å›¾
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('æ•°æ®ç›¸å…³æ€§çƒ­åŠ›å›¾')
plt.show()'''
        }
        
    elif 'å›¾è¡¨' in query_lower or 'å¯è§†åŒ–' in query_lower:
        return {
            'analysis': """ğŸ“Š æ•°æ®å¯è§†åŒ–åˆ†æ

å·²ä¸ºæ‚¨ç”Ÿæˆå¤šç§å¯è§†åŒ–å›¾è¡¨ï¼š

ğŸ¨ ç”Ÿæˆçš„å›¾è¡¨ï¼š
1. ğŸ“ˆ é”€å”®è¶‹åŠ¿çº¿å›¾ - æ˜¾ç¤ºæœˆåº¦å˜åŒ–
2. ğŸ“Š äº§å“ç±»åˆ«é¥¼å›¾ - ç±»åˆ«åˆ†å¸ƒ
3. ğŸ“‹ é”€å”®é¢åˆ†å¸ƒç›´æ–¹å›¾ - é‡‘é¢åˆ†å¸ƒ
4. ğŸ”¥ ç›¸å…³æ€§çƒ­åŠ›å›¾ - å˜é‡å…³ç³»

ğŸ’¡ å¯è§†åŒ–æ´å¯Ÿï¼š
â€¢ æ˜æ˜¾çš„å­£èŠ‚æ€§é”€å”®æ¨¡å¼
â€¢ äº§å“ç±»åˆ«åˆ†å¸ƒä¸å‡åŒ€
â€¢ å¤§éƒ¨åˆ†ä¸ºä¸­å°é¢è®¢å•
â€¢ å˜é‡é—´å­˜åœ¨æœ‰è¶£å…³è”

æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆï¼Œå¯ç”¨äºæŠ¥å‘Šå±•ç¤ºã€‚""",
            
            'code': '''import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']

# åˆ›å»ºå­å›¾
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. é”€å”®è¶‹åŠ¿
monthly_sales = df.groupby('month')['sales'].sum()
axes[0,0].plot(monthly_sales.index, monthly_sales.values, marker='o')
axes[0,0].set_title('æœˆåº¦é”€å”®è¶‹åŠ¿')

# 2. ç±»åˆ«åˆ†å¸ƒ
category_counts = df['category'].value_counts()
axes[0,1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')
axes[0,1].set_title('äº§å“ç±»åˆ«åˆ†å¸ƒ')

# 3. é”€å”®é¢åˆ†å¸ƒ
axes[1,0].hist(df['sales_amount'], bins=30, alpha=0.7)
axes[1,0].set_title('é”€å”®é¢åˆ†å¸ƒ')

# 4. ç›¸å…³æ€§çƒ­åŠ›å›¾
corr = df.select_dtypes(include=[np.number]).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', ax=axes[1,1])
axes[1,1].set_title('ç›¸å…³æ€§çƒ­åŠ›å›¾')

plt.tight_layout()
plt.show()'''
        }
    
    else:
        return {
            'analysis': f"""ğŸ¤– AIåˆ†æå›å¤

é’ˆå¯¹æ‚¨çš„é—®é¢˜ï¼š"{query}"

åŸºäºä¸Šä¼ çš„æ–‡ä»¶ "{file_info['original_name']}"ï¼Œæˆ‘æä¾›ä»¥ä¸‹åˆ†æï¼š

ğŸ“Š æ•°æ®æ¦‚å†µï¼š
â€¢ æ–‡ä»¶å¤§å°: {file_info['size']} bytes
â€¢ ä¸Šä¼ æ—¶é—´: {file_info['upload_time']}
â€¢ å¤„ç†çŠ¶æ€: {"å·²å¤„ç†" if file_info.get('processed') else "å¾…å¤„ç†"}

ğŸ” å»ºè®®çš„åˆ†ææ–¹å‘ï¼š
1. åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯åˆ†æ
2. æ•°æ®è´¨é‡æ£€æŸ¥
3. å¼‚å¸¸å€¼æ£€æµ‹
4. ç›¸å…³æ€§åˆ†æ
5. è¶‹åŠ¿åˆ†æ
6. å¯è§†åŒ–å±•ç¤º

ğŸ’¡ æ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹å…·ä½“é—®é¢˜ï¼š
â€¢ "åˆ†æåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯"
â€¢ "æ£€æµ‹å¼‚å¸¸å€¼å’Œç¦»ç¾¤ç‚¹"
â€¢ "åˆ†ææ•°æ®ç›¸å…³æ€§"
â€¢ "ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"

æˆ‘éšæ—¶å‡†å¤‡ä¸ºæ‚¨æä¾›æ›´è¯¦ç»†çš„åˆ†æï¼""",
            
            'code': f'''import pandas as pd
import numpy as np

# è¯»å–Excelæ–‡ä»¶
df = pd.read_excel('{file_info['original_name']}')

# åŸºæœ¬ä¿¡æ¯
print("æ–‡ä»¶åŸºæœ¬ä¿¡æ¯:")
print(f"è¡Œæ•°: {{df.shape[0]}}")
print(f"åˆ—æ•°: {{df.shape[1]}}")

# æ•°æ®é¢„è§ˆ
print("æ•°æ®é¢„è§ˆ:")
print(df.head())

# æ•°æ®ç±»å‹
print("æ•°æ®ç±»å‹:")
print(df.dtypes)'''
        }


@app.route('/api/files')
def list_files():
    """List all uploaded files."""
    files = []
    for file_id, file_info in uploaded_files.items():
        files.append({
            'file_id': file_id,
            'filename': file_info['original_name'],
            'size': file_info['size'],
            'upload_time': file_info['upload_time'],
            'processed': file_info['processed']
        })
    
    return jsonify({'files': files})


@app.route('/api/files/<file_id>', methods=['DELETE'])
def delete_file(file_id):
    """Delete uploaded file."""
    try:
        if file_id not in uploaded_files:
            return jsonify({'error': 'File not found'}), 404
        
        file_info = uploaded_files[file_id]
        
        # Delete physical file
        if os.path.exists(file_info['file_path']):
            os.remove(file_info['file_path'])
        
        # Remove from memory
        del uploaded_files[file_id]
        
        return jsonify({'success': True, 'message': 'File deleted successfully'})
        
    except Exception as e:
        return jsonify({'error': f'Delete failed: {str(e)}'}), 500


if __name__ == '__main__':
    # Initialize agent system
    if AGENT_AVAILABLE:
        print("Attempting to initialize agent system...")
        try:
            success = asyncio.run(initialize_agent_system())
            if success:
                print("âœ… Agent system initialized successfully!")
            else:
                print("âš ï¸  Agent system initialization failed, running in mock mode")
        except Exception as e:
            print(f"âš ï¸  Agent system initialization error: {e}")
            print("Running in mock mode...")
    else:
        print("âš ï¸  Agent system not available, running in mock mode")
    
    print(f"Upload folder: {app.config['UPLOAD_FOLDER']}")
    print("Starting Flask server...")
    app.run(debug=True, host='0.0.0.0', port=5000)